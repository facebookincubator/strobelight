#!/usr/bin/env python3
"""
CUDA Trace Parser - Parses CUDA trace files generated by BPF programs
"""

import re
import pandas as pd
import json
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict, Counter
import numpy as np
import os
import argparse
import sys

class CUDATraceParser:
    """Parser for CUDA trace files generated by BPF programs"""
    
    def __init__(self, trace_file_path):
        """Initialize the parser with the path to the trace file"""
        self.trace_file_path = trace_file_path
        self.entries = []
        self.df = None
        self.start_time = None
        
    def parse(self):
        """Parse the trace file and extract structured data"""
        print(f"Parsing trace file: {self.trace_file_path}")
        
        with open(self.trace_file_path, 'r') as f:
            content = f.read()
        
        # Extract the start time
        start_time_match = re.search(r'Started profiling at (.+)', content)
        if start_time_match:
            self.start_time = datetime.strptime(start_time_match.group(1), '%a %b %d %H:%M:%S %Y')
        
        # Split the content by the separator
        entries_raw = content.split('-' * 80)
        
        # Skip the header information
        entries_raw = [entry for entry in entries_raw if '[TIMESTAMP]' in entry]
        
        for entry in entries_raw:
            parsed_entry = self._parse_entry(entry)
            if parsed_entry:
                self.entries.append(parsed_entry)
        
        print(f"Parsed {len(self.entries)} trace entries")
        
        # Convert to DataFrame for easier analysis
        self.df = pd.DataFrame(self.entries)
        
        # Convert timestamp to datetime and calculate relative time
        if 'timestamp' in self.df.columns:
            self.df['datetime'] = pd.to_datetime(self.df['timestamp'])
            if self.start_time:
                self.df['relative_time'] = (self.df['datetime'] - pd.to_datetime(self.start_time)).dt.total_seconds()
            else:
                # If no start time, use the first timestamp as reference
                first_time = self.df['datetime'].min()
                self.df['relative_time'] = (self.df['datetime'] - first_time).dt.total_seconds()
        
        return self.df
    
    def _parse_entry(self, entry):
        """Parse a single trace entry"""
        if not entry.strip():
            return None
        
        result = {}
        
        # Extract timestamp
        timestamp_match = re.search(r'\[TIMESTAMP\] (.+)', entry)
        if timestamp_match:
            result['timestamp'] = timestamp_match.group(1)
        
        # Extract process info
        process_match = re.search(r'\[PROCESS\] (.+) \[(\d+)\] CUDA API EventType (\d+)', entry)
        if process_match:
            result['process_name'] = process_match.group(1)
            result['pid'] = int(process_match.group(2))
            result['event_type'] = int(process_match.group(3))
        
        # Extract CUDA API call type
        cuda_call_match = re.search(r'\[(CUDA_[A-Z_]+)\]', entry)
        if cuda_call_match:
            result['cuda_call'] = cuda_call_match.group(1)
        
        # Extract grid and block dimensions for kernel launches
        if 'cuda_call' in result and result['cuda_call'] == 'CUDA_LAUNCH_KERNEL':
            grid_match = re.search(r'Grid: \(([^)]+)\)', entry)
            block_match = re.search(r'Block: \(([^)]+)\)', entry)
            
            if grid_match:
                grid_dims = grid_match.group(1).split(',')
                result['grid_x'] = int(grid_dims[0]) if grid_dims[0].strip().isdigit() else grid_dims[0].strip()
                result['grid_y'] = int(grid_dims[1]) if grid_dims[1].strip().isdigit() else grid_dims[1].strip()
                result['grid_z'] = int(grid_dims[2]) if grid_dims[2].strip().isdigit() else grid_dims[2].strip()
            
            if block_match:
                block_dims = block_match.group(1).split(',')
                result['block_x'] = int(block_dims[0]) if block_dims[0].strip().isdigit() else block_dims[0].strip()
                result['block_y'] = int(block_dims[1]) if block_dims[1].strip().isdigit() else block_dims[1].strip()
                result['block_z'] = int(block_dims[2]) if block_dims[2].strip().isdigit() else block_dims[2].strip()
        
        # Extract arguments
        args_match = re.search(r'\[ARGS\] (.+)', entry)
        if args_match and args_match.group(1).strip():
            result['args'] = args_match.group(1).strip()
            
            # Try to extract kernel name from args
            kernel_name_match = re.match(r'^(\w+)', result['args'])
            if kernel_name_match:
                result['kernel_name'] = kernel_name_match.group(1)
        
        # Extract stack trace
        stack_trace_match = re.search(r'\[STACK_TRACE\]\s+([\s\S]+?)(?=\Z|^\[)', entry, re.MULTILINE)
        if stack_trace_match:
            stack_trace = stack_trace_match.group(1).strip().split('\n')
            result['stack_trace'] = [frame.strip() for frame in stack_trace if frame.strip()]
            
            # Extract the CUDA API function from the stack trace
            if result['stack_trace']:
                result['cuda_api_function'] = result['stack_trace'][0].strip()
        
        return result

    def save_to_json(self, output_path):
        """Save the parsed data to a JSON file"""
        if not self.entries:
            print("No entries to save. Run parse() first.")
            return
        
        # Convert DataFrame to JSON
        with open(output_path, 'w') as f:
            # Convert to records format for better readability
            json.dump(self.df.to_dict(orient='records'), f, indent=2, default=str)
        
        print(f"Saved parsed data to {output_path}")

if __name__ == "__main__":
    # Parse command line arguments
    parser = argparse.ArgumentParser(description="CUDA Trace Parser")
    parser.add_argument("trace_file", help="Path to the CUDA trace file")
    parser.add_argument("--output", default="parsed_trace.json", help="Output JSON file path")
    
    args = parser.parse_args()
    
    # Use the provided trace file path
    trace_parser = CUDATraceParser(args.trace_file)
    df = trace_parser.parse()
    trace_parser.save_to_json(args.output)
    print(f"Parsing complete. Data saved to {args.output}")
